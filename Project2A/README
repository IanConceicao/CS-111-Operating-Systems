NAME: Ian Conceicao
EMAIL: IanCon234@gmail.com
ID: 505153981

tar -czvf lab2a-505153981.tar.gz lab2_add.c SortedList.h SortedList.c lab2_list.c Makefile lab2_add.csv \
	lab2_list.csv lab2_add-1.png lab2_add-2.png lab2_add-3.png lab2_add-4.png lab2_add-5.png lab2_list-1.png \
	lab2_list-2.png lab2_list-3.png lab2_list-4.png README

-----------------------------
DESCRIPTION OF INCLUDED FILES
-----------------------------

lab2_add.c:
    Source file for multiple threads to add to a counter to observe race conditions.
    Usage: --threads=<numOfThreads> --iterations=<numOfIterations> --yield (if you want a thread to yield) before
    each addition. And finally, --sync=<syncMode> where syncMode can be:
    s: spinning lock
    m: mutex lock
    c: compare and swap

lab2_list.c:
    Source file for multiple threads that implements insert, delete, lookup and length methods for a sorted doubly linked list.
    Usage: --threads=<numOfThreads> --iterations=<numOfIterations> --yield (if you want a thread to yield) before
    each addition. And finally, --sync=<syncMode> where syncMode can be:
    s: spinning lock
    m: mutex lock

Descriptions from spec sheet:

SortedList.h ... a header file (supplied by us) describing the interfaces for linked list operations.
SortedList.c ... a C module that implements insert, delete, lookup, and length methods for a sorted doubly linked list 
(described in the provided header file, including correct placement of yield calls).

lab2_add.csv:
    All of the results for tests. Data is plotted

lab2_list.csv
    All of the results for list tests. Data is plotted by make graph.

Graphs: (Descriptions from the spec sheet)

    lab2_add-1.png ... threads and iterations required to generate a failure (with and without yields)
    lab2_add-2.png ... average time per operation with and without yields.
    lab2_add-3.png ... average time per (single threaded) operation vs. the number of iterations.
    lab2_add-4.png ... threads and iterations that can run successfully with yields under each of the synchronization options.
    lab2_add-5.png ... average time per (protected) operation vs. the number of threads.
    lab2_list-1.png ... average time per (single threaded) unprotected operation vs. number of iterations (illustrating the correction of the per-operation cost for the list length).
    lab2_list-2.png ... threads and iterations required to generate a failure (with and without yields).
    lab2_list-3.png ... iterations that can run (protected) without failure.
    lab2_list-4.png ... (length-adjusted) cost per operation vs the number of threads for the various synchronization option

Makefile:
    Usage:
        make (builds source files)
        make tests (runs test results into .csv's)
        make graphs (plots graphs)
        make dist (makes tar)
        make clean (cleans directory)

---------------------------
    QUESTION ANSWERS
---------------------------

Question 2.1.1
--------------
The chances that more than 1 thread want to execute the same section of the program at a time are low. Especially
when there are a small number of threads. When the iteration is increased, while the chance of two threads reading and
writing counter at the same time per iteration are still low, because the threads are doing the reading and writing
more frequently, errors are seen.

Question 2.1.2
--------------
Yield runs are much slower because the running thread gives up control unnecessarily, and the context switch incurs
extra time for changing the stack pointer, program counter, updating the waiting queue etc. It is not possible to
get per-operation timings if we are using the --yield option because we could not predict or deduct the timing
cost of each context switch.

Question 2.1.3
--------------
The average cost per operation drops with increasing iterations because the overhead of creating and destroying
threads starts to become less and less significant the more operations we perform. With this in mind, the "correct"
cost per operation can be determined by running the program with a very large iteration value, making the overhead
involved with creating threads completely insignificant.


Question 2.1.4
--------------
All of the options run similarly for low numbers of threads because when there are few threads there are few chances
of multiple threads encountering the critical section at the same time and blocking each other. As the number of 
threads increase, the three protected operations slow down because there are more locking conflicts, and more threads 
have to wait longer.



Question 2.2.1
--------------
In both add and list the cost per operation seems to grow as a function of the numbe of threads. A seen in lab2_add-5.png and lab2_list-4.png,
the graphs look linear on a log scale, implying the growth is exponential with respect to the number of threads. It makes sense for the cost
of an operation to grow exponentially with the number of threads because more threads form convoys for locks, as they fight over holding
critical sections.


Question 2.2.2
-------------
Analyzing image lab2_list-4.png, the spin lock line (green line) clearly grows far worse per thread than the mutex line (blue line). The 
cost axis is on a log scale, showing spin blocks scale worser on a much large scope of significance than mutexes. Spin locks are dangerously 
exponentially meanwhile mutexes are still exponential but not nearly as bad. Spin locks poor scalability can be attributed to burning up
CPU cycles while waiting, meanwhile mutexes go into a queue and wait to be signalled.






